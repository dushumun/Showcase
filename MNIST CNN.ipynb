{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple demonstrations of CNN for MNIST digit classification\n",
    "\n",
    "Demonstration of building a CNN to classify handwritten digits through supervised learning on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DUSHUMUN\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Libraries used\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib as plt\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the data set, contains 60k Training and 10k Testing Samples, each in grey scale and of 28x28 resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining features of data set used for building network architecture\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalising x input values\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model, based loosely on VGG design principles of stacking multiple 3x3 conv layers in order to take advantage of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3),\n",
    "                activation = 'relu',\n",
    "                input_shape = input_shape,))\n",
    "model.add(Conv2D(32, (3,3),\n",
    "                 activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                 activation = 'relu'))\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                 activation = 'relu'))\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                 activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent Optimiser used for training. Makes use of a momentum coeffecient in order to overcome local optima in the gradient descent method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = SGD(lr = 0.01, momentum = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer = opt, metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 155s 3ms/step - loss: 0.3389 - acc: 0.8895 - val_loss: 0.0633 - val_acc: 0.9796\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 153s 3ms/step - loss: 0.0902 - acc: 0.9719 - val_loss: 0.0396 - val_acc: 0.9882\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 154s 3ms/step - loss: 0.0636 - acc: 0.9807 - val_loss: 0.0385 - val_acc: 0.9879\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 154s 3ms/step - loss: 0.0532 - acc: 0.9838 - val_loss: 0.0306 - val_acc: 0.9909\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 155s 3ms/step - loss: 0.0445 - acc: 0.9860 - val_loss: 0.0270 - val_acc: 0.9911\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 166s 3ms/step - loss: 0.0377 - acc: 0.9889 - val_loss: 0.0273 - val_acc: 0.9909\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.0331 - acc: 0.9894 - val_loss: 0.0228 - val_acc: 0.9926\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 177s 3ms/step - loss: 0.0284 - acc: 0.9915 - val_loss: 0.0230 - val_acc: 0.9924\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 161s 3ms/step - loss: 0.0267 - acc: 0.9915 - val_loss: 0.0297 - val_acc: 0.9899\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 175s 3ms/step - loss: 0.0248 - acc: 0.9919 - val_loss: 0.0222 - val_acc: 0.9922\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 10,\n",
    "                    verbose = 1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.022238820368500455\n",
      "Test accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Through a short training time and relatively simple CNN architecture, the model has produced over 99% accuracy! Over 2% increase when compared to the MLP model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
